{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import cv2\n",
    "import shutil\n",
    "import PIL\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES_PER_CLASS = 10_000\n",
    "NUM_VAL = 50 * 340"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data from csvs\n",
    "\n",
    "This block generates the test and train data files and should only need to be run chen generating new files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/txt/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir data/txt/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_txts_from_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for row in df.sample(NUM_SAMPLES_PER_CLASS).iterrows():\n",
    "        example = {\n",
    "            'countrycode': row[1].countrycode,\n",
    "            'drawing': json.loads(row[1].drawing),\n",
    "            'key_id': row[1].key_id,\n",
    "            'recognized': row[1].recognized,\n",
    "            'word': '_'.join(row[1].word.split())\n",
    "        }\n",
    "        with open(f'data/txt/train/{example[\"word\"]}_{example[\"key_id\"]}.txt', mode='w') as f: json.dump(example, f)\n",
    "            \n",
    "def create_test_txts_from_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for row in df.iterrows():\n",
    "        example = {\n",
    "            'countrycode': row[1].countrycode,\n",
    "            'drawing': json.loads(row[1].drawing),\n",
    "            'key_id': row[1].key_id,\n",
    "            'word': 'unknown'\n",
    "        }\n",
    "        with open(f'data/txt/test/{example[\"word\"]}_{example[\"key_id\"]}.txt', mode='w') as f: json.dump(example, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time create_test_txts_from_df('data/test_simplified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing it like this so %time works properly and I can have a progress indicator.\n",
    "def create_train_data():\n",
    "    i = 1\n",
    "    for p in Path('data/train').iterdir(): \n",
    "        %time create_train_txts_from_df(p)\n",
    "        print(i, \"/\", len(os.listdir(Path('data/train'))))\n",
    "        print(str(p)[45:])\n",
    "        i += 1\n",
    "    return \"Done!\"\n",
    "\n",
    "%time create_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ImageDataBunch using the data block API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis is the image size that will be created for the data loader\n",
    "sz = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 7.21 s, total: 49.1 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%time inp_list = InputList.from_folder('data/txt/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 120 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%time label_list = inp_list.label_from_re('\\A([a-zA-Z-_]*)_\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(label_list.files.shape[0])\n",
    "np.random.shuffle(idxs)\n",
    "val_fns = set(label_list.files[idxs[:NUM_VAL]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 s, sys: 344 ms, total: 5.14 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%time split = label_list.split_by_files(val_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 232 ms, total: 1.51 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = split.add_test(InputList.from_folder('data/txt/test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = set(label_list.labels)\n",
    "\n",
    "# can this change if you train on different data?\n",
    "# could this be useful for prediction / making a submission?\n",
    "#\n",
    "# might want to comment out the creation and saving and only leave loading uncommented on consecutive runs\n",
    "class2idx = {c: i for i, c in enumerate(classes)}\n",
    "idx2class = {i: c for c, i in class2idx.items()}\n",
    "pd.to_pickle(class2idx, 'data/class2idx.pkl')\n",
    "pd.to_pickle(idx2class, 'data/idx2class.pkl')\n",
    "\n",
    "class2idx =pd.read_pickle('data/class2idx.pkl')\n",
    "idx2class = pd.read_pickle('data/idx2class.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/gaborfodor/greyscale-mobilenet-lb-0-892\n",
    "BASE_SIZE = 256\n",
    "def list2drawing(raw_strokes, size=sz, lw=6, time_color=False):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "#     img = cv2.copyMakeBorder(img,4,4,4,4,cv2.BORDER_CONSTANT)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing2tensor(drawing):\n",
    "    rgb = cv2.cvtColor(drawing,cv2.COLOR_GRAY2RGB)\n",
    "    rgb = rgb.transpose(2,0,1).astype(np.float32)\n",
    "    return torch.from_numpy(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickdrawDataset(DatasetBase):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__(x, y, classes=list(class2idx.keys()), c=340, task_type=TaskType.Single, class2idx=class2idx)\n",
    "    def _get_x(self,i):\n",
    "        with open(self.x[i]) as f: j = json.load(f)\n",
    "        drawing = list2drawing(j['drawing'])\n",
    "        tensor = drawing2tensor(drawing)\n",
    "        return Image(tensor.div_(255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 840 ms, sys: 4 ms, total: 844 ms\n",
      "Wall time: 845 ms\n"
     ]
    }
   ],
   "source": [
    "%time dss = split.datasets(QuickdrawDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dss.train_ds, batch_size=bs, shuffle=True, num_workers=12)\n",
    "valid_dl = DataLoader(dss.valid_ds, batch_size=2*bs, shuffle=False, num_workers=12)\n",
    "test_dl = DataLoader(dss.test_ds, batch_size=2*bs, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch = ImageDataBunch(train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_bunch.show_batch(rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same argument as above - you might want to save this value for later use\n",
    "batch_stats = data_bunch.batch_stats()\n",
    "pd.to_pickle(batch_stats, 'data/batch_stats.pkl')\n",
    "batch_stats = pd.read_pickle('data/batch_stats.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch.normalize(batch_stats);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res34-128-10k-cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map3(preds, targs):\n",
    "    predicted_idxs = preds.sort(descending=True)[1]\n",
    "    top_3 = predicted_idxs[:, :3]\n",
    "    res = mapk([[t] for t in targs.cpu().numpy()], top_3.cpu().numpy(), 3)\n",
    "    return torch.tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data_bunch, models.resnet34, metrics=[accuracy, map3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2:09:35\n",
      "epoch  train_loss  valid_loss  accuracy  map3    \n",
      "1      1.172541    0.964299    0.726177  0.805127  (32:26)\n",
      "2      1.034310    0.859165    0.751118  0.825559  (32:22)\n",
      "3      0.970942    0.798923    0.767000  0.838941  (32:23)\n",
      "4      0.929214    0.779594    0.773647  0.843578  (32:23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#learn.fit_one_cycle(2)\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{name}-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationLearner(data=<fastai.vision.data.ImageDataBunch object at 0x7f53d8817080>, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Lambda()\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=340, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function cross_entropy at 0x7f546ac8e488>, metrics=[<function accuracy at 0x7f54642ba840>, <function map3 at 0x7f5463799f28>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace)\n",
       "  (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU(inplace)\n",
       "  (22): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (28): ReLU(inplace)\n",
       "  (29): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (30): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace)\n",
       "  (34): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (35): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): ReLU(inplace)\n",
       "  (39): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "), Sequential(\n",
       "  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace)\n",
       "  (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): ReLU(inplace)\n",
       "  (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): ReLU(inplace)\n",
       "  (25): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): ReLU(inplace)\n",
       "  (30): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (34): ReLU(inplace)\n",
       "  (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (37): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): ReLU(inplace)\n",
       "  (42): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (43): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (46): ReLU(inplace)\n",
       "  (47): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Lambda()\n",
       "  (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25)\n",
       "  (5): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5)\n",
       "  (9): Linear(in_features=512, out_features=340, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(f'{name}-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 4:27:19\n",
      "epoch  train_loss  valid_loss  accuracy  map3    \n",
      "1      0.813238    0.732632    0.780824  0.850588  (44:32)\n",
      "2      0.719399    0.658892    0.802059  0.867490  (44:34)\n",
      "3      0.632875    0.596145    0.819471  0.880000  (44:33)\n",
      "4      0.537060    0.564679    0.831588  0.888971  (44:32)\n",
      "5      0.449523    0.540408    0.839529  0.894725  (44:32)\n",
      "6      0.372626    0.553829    0.838294  0.893784  (44:33)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, max_lr=6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'{name}-stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = np.argsort(preds.numpy())[:, ::-1][:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(top_3.shape[0]):\n",
    "    labels.append(' '.join([learn.data.train_ds.classes[idx] for idx in top_3[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pants shorts underwear'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "image/png": "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\n",
      "text/plain": [
       "Image (3, 128, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl.dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ids = [path.stem.split('_')[1] for path in learn.data.test_dl.dl.dataset.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'subs', exist_ok=True)\n",
    "sub = pd.DataFrame({'key_id': key_ids, 'word': labels})\n",
    "sub.to_csv(f'subs/{name}.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9413660627454708</td>\n",
       "      <td>horse zebra cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9738540686991405</td>\n",
       "      <td>pants shorts underwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9865207604494741</td>\n",
       "      <td>knee leg elbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9581975421394765</td>\n",
       "      <td>sweater jacket t-shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9721368529374760</td>\n",
       "      <td>mug cup coffee_cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                    word\n",
       "0  9413660627454708         horse zebra cow\n",
       "1  9738540686991405  pants shorts underwear\n",
       "2  9865207604494741          knee leg elbow\n",
       "3  9581975421394765  sweater jacket t-shirt\n",
       "4  9721368529374760      mug cup coffee_cup"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by otherusers on this system! To fix this, you can run'chmod 600 /home/jupyter/.kaggle/kaggle.json'\n",
      "100%|███████████████████████████████████████| 1.50M/1.50M [00:06<00:00, 236kB/s]\n",
      "Successfully submitted to Quick, Draw! Doodle Recognition Challenge"
     ]
    }
   ],
   "source": [
    "#!kaggle competitions submit -c quickdraw-doodle-recognition -f subs/{name}.csv.gz -m \"{name}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
